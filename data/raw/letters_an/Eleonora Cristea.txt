Since my [university] enrolment back in 2020, I have been keen on obtaining as much practical experience in NLP as I could. Throughout my university years, I studied hard to gain more insights into how I could apply my skills to solve some real-world problems and advance the research in NLP in a meaningful way. Although I consider the knowledge received at university, by all accounts, valuable, it is obvious that for me to become a world-class expert in NLP and ML, I have to spend a significant amount of time doing hands-on NLP projects, talking to like-minded people, and learning from experts working in the industry. For that reason, it is quite crucial for me to participate in an activity that encompasses all these aspects. I assume that SMILES summer school would grant me this invaluable opportunity.
It is worth mentioning that I do have some experience in NLP and ML in general. My first coursework was dedicated to exploring the existing language corpora used for training language models. This was my first experience applying the knowledge I received in my university lectures and seminars to working on a project that was related to real-world tasks in NLP. I used regular expressions, NLTK, pandas, and pymorphy libraries for working on this project. The result of my first coursework was an extensive overview of the existing language corpora and the tools implemented to collect them.
Building on this experience, my following coursework was dedicated to collecting my own language corpus that consisted of Russian texts related to the mining industry. The goal was to create a domain-specific corpus that could be later used to fine-tune a language model so that it could answer questions related to this specific domain. This project presented me an opportunity to learn data scraping, working with several Python libraries (requests, Beautiful Soup, spaCy, transformers, torch), and fine-tuning a language model.
My final graduation academic work was dedicated to fine-tuning a RuBERT model to perform a news clusterization task. The task can be formulated in the following way: given a pair of texts, the model must decide if they are related to one topic or not. The main problem was due to the fact that the texts were short (news headlines), so there were not many cues for the model to ascertain whether they are related or not. For this project, I gathered my own Russian news text dataset, preprocessed it, performed several different clusterization techniques (DBSCAN, HAC, k-means clustering), and implemented dimensionality-reduction methods (PCA) to tackle the curse of dimensionality. In order to receive a high-quality clusterization, it was decided to use LLM markup that was performed through the OpenAI API. The subset of the markup was verified by me. As a result, a RuBERT model was trained with an average 0.64 F1-score metric for each class (0 and 1).
Following my graduation, I started to actively seek job opportunities. In September 2024, I managed to fill the open role at [compaany], where I was tasked with working with large volumes of unstructured text data gathered by the company. Primarily, I focused on preprocessing and annotating these datasets in order to further the development of an AI assistant the company intended to use for interaction with clients. My job duties also included creating and testing the prompts. As part of my work routine, I collaborated extensively with ML engineers, linguists, and product analysts to better understand the mechanisms underlying the project we were working on.
In addition to my academic and professional experience, I also actively engage in extracurricular activities. Recently, I participated in the AI Workshop Week at [university], as well as the LLM Coding Challenge Marathon organized by [compaany]. At the workshop, me and my team were developing an AutoML pipeline for classification based on the resources at hand. Three general approaches were tested: classic ML methods, using PEFTs for BERT, and LLM-based ones. The research is still ongoing, so there are only preliminary results to be shared: BERT coupled with PEFTs outperformed midsized LLMs (24B parameters) significantly.
As for the hackathon, the task was to present a solution that would automate the manual transfer of all the individual daily reports made by agronomists into a single table. Our goal was to build a system that could extract relevant information from unstructured text messages and structure it in a consistent way. The output table is meant to be further examined by a supervisor. Our solution was ranked 8th out of 18 finalists, with an initial pool of 40 teams enrolled in the contest.
I am looking forward to participating in SMILES summer school, as I expect to get acquainted with peers who share my interests and are open to collaboration on future projects. Furthermore, I expect to gain insights into modern ML and NLP academic research, as well as conduct my own research that could be later presented at a Core A conference. Moreover, I believe that taking part in the summer school would further my career development, as I am striving to become an expert in the field of natural language processing and machine learning. In 2â€“3 years, I am planning to become a Middle+ NLP Engineer, contributing to both academic research and industry projects. My ultimate goal is to work at the crossroads of academic research and industry application and I think that SMILES summer school will present me with an opportunity to acquire the necessary experience for that.
In conclusion, SMILES summer school would be a perfect spot for me to grow faster and better. The combination of expert instruction, workshops, and networking opportunities would provide an ideal setting for acquiring new skills and expanding my knowledge.
Thank you for considering my application. I would love to be a part of your community.
Best regards,
[name] [surname]