Dear [name],
I am writing to express my interest in participating in the SMILES program. My name is [name], and I am currently a dedicated researcher in the "Domain Specific NLP" team at [compaany] and an undergraduate student pursuing Applied Mathematics and Informatics at [location].
My journey into machine learning research was driven by a desire to address fundamental challenges in the field, which led me to transfer into my current program at [location] and join [compaany] under the guidance of Dr. [name]. In this role, I quickly started doing relevant research, where I recently led a project investigating controlled unlearning in Vision Language models, resulting in my first-author paper, "CLEAR: Character Unlearning in Textual and Visual Modalities." This work, currently under review at ACL Rolling Review, has already gathered 6 citations, and even some work has been built upon it ([url]).
Notably, one of the paper's supervisors and co-authors is Dr. [name], whom I am excited to see listed as one of the main speakers at SMILES. This project provided me with invaluable end-to-end research experience â€“ from hypothesis formulation and experimental design (including coding) to coordinating a research group and drafting the manuscript.
Beyond unlearning, my current passion lies in the mechanistic interpretability of large language models. I am particularly fascinated by how transformer architectures learn and function internally. This interest has led to concrete research results; for example, I am the second author on the paper "I Have Covered All the Bases Here: Interpreting Reasoning Features in Large Language Models via Sparse Autoencoders" - another collaboration with Dr. [name]'s team. In this work, we utilized Sparse Autoencoders (SAEs) to identify and validate specific features within DeepSeek-R1 models that correlate directly with reasoning abilities, demonstrating that manipulating these features can enhance reasoning performance mechanistically. Additionally, I am exploring the application of SAEs to model reward functions in Reinforcement Learning for reasoning tasks. Specifically, my exploration of reward models revealed SAE features that highly correlate with the reward signal; I could reconstruct the reward using these features with an R-squared value up to 0.9. Furthermore, I found these same features present in the base model itself. This finding suggests the potential to move beyond training separate reward models and instead utilize the activations of these intrinsic features directly as the reward signal. These interests in interpretability, reasoning, and alignment directly overlap with SMILES' focus on LLMs and advanced AI techniques.
Complementing my research is a strong foundation in practical ML engineering. During my two years as an ML Engineer at [compaany], I gained significant experience in writing production-quality code, building ML services, and deploying models, including transformer-based systems that are still operational. My technical skills are further evidenced by projects such as replicating paper for RLHF loss analysis ([url]), contributing T5 model support to the TransformerLens interpretability library ([url]), and the codebase for our unlearning research ([url]). I am confident in my ability to actively contribute to the practical seminars and hackathons at SMILES.
I also strongly believe in the importance of sharing my knowledge. I have actively sought opportunities to teach and mentor, including developing and delivering a course on neural networks at the Center of Pedagogical Excellence school ([url]), mentoring student projects at [compaany] summer and AI360 winter schools (one of which won "Best Student Project"), and serving as an expert for the "Big Challenges" program. These experiences have honed my ability to communicate complex ideas clearly and work effectively in team settings.
SMILES-2025 represents an unparalleled opportunity to deepen my understanding of generative AI, learn from leading experts, and collaborate with talented students from both [location] and [location]. The focus on practical application through team projects addressing real-world challenges is particularly appealing, offering a chance to apply theoretical knowledge and technical skills in a dynamic environment. The emphasis on international cooperation and knowledge exchange resonates deeply with my belief in the power of collaborative research to drive progress in AI.
In conclusion, my research experience in LLM unlearning and interpretability, coupled with strong technical skills and a passion for collaborative knowledge sharing, makes me a well-suited candidate for SMILES-2025. I am eager to contribute my perspective, learn from the expertise present, and build connections within this international community. Thank you for considering my application. I look forward to the possibility of joining you this summer.
Sincerely,
[name]