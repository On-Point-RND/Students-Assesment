I, [name], am a second-year PhD student in the “1.2.1 Artificial Intelligence and Machine Learning” program at [location]. My thesis focuses on “Methods and Algorithms for Generative Design of Physical Objects with Graph Structure Representation Using Deep Learning Models.”
Throughout my academic journey, I’ve been involved in various projects related to generative and predictive artificial intelligence (AI) in industry and the design of multi-agent systems based on large language models (LLMs).
My research began with applying evolutionary generative design algorithms to create coastal defense structures (breakwaters), flow channel labyrinths for blood spleen nano-filters, and solving inverse defectoscopy problems.
Later, I transitioned to deep learning. Collaborating with a team of chemists, I developed neural networks using GANs and Transformers to generate molecular sequences, leveraging the [compaany] library.
More recently, I’ve been working on a multi-agent system based on LLMs that can solve chemical problems on demand. This project allowed me to apply my expertise in generative design and gain experience in building and deploying LLM-based applications using Docker.
One of my key achievements was developing a Transformer-based neural network architecture that outperformed existing molecular search methods. This research was accepted at the NeurIPS international conference in 2024.
I am actively developing, implementing, and training generative deep learning models based on convolutional, diffusion, and Transformer architectures. I also have a strong background in generative design methods using evolutionary optimization algorithms.
My latest research initiative aims to develop a drug discovery platform that uses advanced generative AI techniques to target specific molecular properties. To date, existing models often overlook essential molecular characteristics, which limits their usefulness in real-world drug development. The most promising approaches in molecule generation include recurrent neural networks, GANs, evolutionary optimization algorithms, and attention-based models like Transformers.
My proposed research focuses on developing hybrid generative methods that combine evolutionary algorithms and Transformer models using a conditional block to establish correlations between molecular structures and their properties. This approach has multiple applications:
1. Distilling evolutionary algorithms into Transformer models, combining the creative capabilities of evolutionary methods with the generalization and efficiency of Transformers.
2. Sequential generation and optimization of molecules, enabling faster and more pharmacologically relevant outputs.
Another advantage of this approach is the ability to train Transformer models without relying on pre-existing datasets. This is done by iteratively generating molecules with evolutionary algorithms and then using them to train the network.
Some of these methods were previously developed and validated in my co-crystal discovery work, culminating in the publication of the paper “Hybrid Generative AI for De Novo Design of Co-Crystals with Enhanced Tabletability.”
I hope to deepen my expertise in generative AI methods at the [compaany] summer school and connect with like-minded researchers to further develop this hybrid generative AI framework.