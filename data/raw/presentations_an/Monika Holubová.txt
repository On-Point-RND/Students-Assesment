Topics: Safe AI, Generative AI, Multimodal approaches
Deep into deepfakes: modern approaches
for recognizing artificial photo and videos
[name] Polyakova
[institution]
Introduction
Deepfake - generated synthetic instances of data that pass for real data (mainlly photo & videos)
• Cinema & Entertainment • Fake news
• Enhancement & validation of ML algorithms • Threat to personal safety
• Education • Forgery of documents and evidence
• Gamedev • Insulting the personality and reputation
Educating public about capabilities and dangers of synthetic media is
not enough. There is a need of recognizing deepfakes, no matter how
visually convincing they are. The cost can be both reputational and
financial.
Goal: provide the review of modern approaches for recognizing artificial visual content
[surname], [surname] & [surname] & [surname]. (2020). DeepFake Detection Algorithms: A Meta-
Analysis. 43-48. 10.1145/3421515.3421532.
Methods
* compiled by the author
1. Analysis of artifacts and anomalies
Identifying artifacts that occur during the creation of deepfakes, as well as on
+
detecting inconsistencies in images/videos that are not found in real media.
2. Physiological and biometric features and signs
Using knowlage about physiology and biometric characteristics to identify defects.
+ Deepfakes often do not reproduce realistically micro-movements, blinking, and other
physiological processes.
3. Multimodal analysis
Combining information from various modalities (image, sound, text) to increase the
accuracy of detecting deepfakes.
Deep into deepfakes: modern approaches
Analysis of artifacts and
for recognizing artificial photo and videos
anomalies
[name] Polyakova
[institution]
Learning on Gradients: Generalized Artifacts
Reprresentation for GAN-Generated Images Detection, 2021
“Pretrained CNN model is employed as a transformation model to convert images into
gradients. Subsequeentl,y, it’s possible to leverage these gradients to present the
generalized artifacts, which are fed into the classifier to ascertain the authenticity of the
images”
Result: new detector architecture with the state-of-the-art performaance with a remarkable gain of
11.4%
[surname], [surname], [surname] & [surname]. (2021). Learning on Gradients: Generalized Artifacts Representation for
GAN-Generated Images Detection. Proceedinings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR)
FreqBlender: Enhancing DeepFake Detection by Blendiing
Frequency Knowledg, 2024
«Faces are composed of three frequency knowledge, which represents semantic
informaation, structuraal information, and noise information, respectively, and the
forgery traces are likel likely hidden in structuraal information»
Result: network consisting of a shared encoder and three decoders to extract correspondiing
frequency knowledge
Also: no ground truth of frequency distribution is provided, thus, authoors propose novel training
strategy
[surname], [surname], [surname] & [surname]. (2024). FreqBlender: Enhancing DeepFake Detection by Blendiing
Frequency Knowledg. Advances in Neural Informaation Processing Systems.
Deep into deepfakes: modern approaches
Physiological and biometric
for recognizing artificial photo and videos
features and signs
[name] Polyakova
[institution]
Face X-ray for More General Face Foigery Detection, 2020
“Face X-ray provides an effeective way for detecting forgery generated by most exisisting
face manipulation algorithm s. Face X-ray is general in the sense that it only assumes the
existence of a blendiing step and does not rely on any knowledg e of the artifacts
associaated with a specific face manipulation technique.
When an image is formed by blendiing two images, there exist intrinsic image
di screpancies across the blendiing boundar y”
Result: general face forgery detector using face X-ray and the detector that can be trained in a
self-supervised manner
[surname], [surname], [surname] & [surname]. (2020). Face X-Ray for More General Face Foigery Detection.
doi:https://doi.org/10.1109/cvpr42600.2020.00505.
Lips Don’t Lie: A Generalisable and Robust Approach to
Face Foigery Detection, 2021
“In this paper, we proposed a novel approach, dubbed LipForensics, for the detection of
forge d face videos. It targets inconsistencies in semantically high-level mouth
movements by leveraging rich representations learne d via lipreading.”
Result: state-of-the-art generali sation to u nseen forgery types while being significa ntly more robus t
than other methods to various common corruptions
[surname], [surname], and [surname]. "Lips Don't Lie: A Generalisable and Robust Approach To Face Foigery Detection."
Proceedinings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR), 2021.
Deep into deepfakes: modern approaches
Multimodal
for recognizing artificial photo and videos
analysis
[name] Polyakova
[institution]
Detecting and Groundiing Multi-Modal Media
Manipulation, 2023
“We perform hierarchi cal manipulation reasoning which explores multi-modal interaction
from shallow to deep levels, along with hierarchi cal manipulation detection and
grounding.”
Result: novel HierArchi cal Multi-modal Manipulation rEasoning tRansforme r (HAMMER) to fully
capture the fine-grained interaction between different modalities. Also, authoors created a first
dataset containing manipulated image-text pairs.
[surname], [surname], et al. (2023) “Detecting and Groundiing Multi-Modal Media Manipulation.”, https://doi.org/10.48550/a rxiv.2304.02556.
AVFF: Audio-Visual Feature Fusion for Video Deepfake
Detection, 2024
“The model learns audio-visual correspo ndences inherent to real videos via a contrasti ve
learning objective and an effective complementary masking and fusion strategy that sits
within an autoencoding objective. The model learns the dependency between “real”
spee ch audio and the correspondi ng visual facial features”
Result: a novel audio-visual complementary masking and feature fusion strategy. Achieved 98.6%
accuracy and 99.1% AUC on the FakeAVCeleb dataset, outp eformi ng the current audio-visual
state-of-the-art by 14.9% and 9.9%, respecti vely.
Figure 2. Audio-Visual Repre sentation Learning Stage
[surname], [surname], Wang, Z., Yang, M., Liu, X., & Wei, X. (2024). Cross-Modal Consis tency Learning for Robust Text-to-Video Retrieval. arXiv
preprint arXiv:2406.02951.
Summary
• Nowadays it’s an “unstoppable competition” between generating realistic photos and
videos and recognizing fake s
• There is no unified way to find deepfakes
• Modern approaches are a mix of picture-speci fic features, biol ological “consis tency” and
multimodal methods
• On my opinio n after review, multimodal approaches are on the “e dg e” now.
Ideas:
• I a lrready know that generated text has smaller topo loogical dimensionality than the real
one, mayb e this approa ch will suit images and videos too?
• It might be interesting to use the metadata for recognizing the fake: parameters of the
camera, geocoodinates etc…



