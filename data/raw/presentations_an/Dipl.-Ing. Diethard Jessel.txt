Text plagiarism detection in the
field of Large Languaage Models
using the Reinforcement Learning
by [name]
1
01
Background
2
Large Languaage Models and plagiarism
- Active development of Large Languaage Models (LLMs) and ease of access to them → large
amount of plagiarized texts
- Applying neural networks to plagiarism detection requires effective text representations
- Idea for buildiing text representations — distilling significant words and removing redundant
words
- How to distill properly? Sequential decision problem → Deep Reinforcement Learning (DRL)
- What plagiarism is? In this research:
- Original text paraphrased by LLM (Type 1 plagiarism)
- Completely new text fully generated by LLM given only the short idea of the original text
(Type 2 plagiarism)
3
02
Deep Reinforcement
Learning
4
Main concepts
- Three basic ML paradigms: supervised learning, unsupervised learning, reinforcement learning
(RL)
- Typical cyclic pipeline:
- Agent takes actions in an environment (based on some policy)
- Environment provides state and reward to the agent
- Agent updates its parameters based on the reward
- DRL incorporates deep learning into RL to allow handling the unstructured input data and
working in high-dimensional state space
5
Basic taxonomy of DRL algorithms
Value-based Policy-based
- Deep Q-Network (DQN) - REINFORCE
- Advantage Actor-Critic (A2C)
- Focuses on estimating the action-value
function (Q-function) - Focuses on estimating the direct policy
- Optimizes policy indirectlly by learning - Can learn stochastic policy
the value first and then using this value
to chooose the optiomal behavior - Adopts automatic exploration
6
03
Metho Methodology &
Implementation
7
Plagiarism generation
- Custom plagiarism definitions require synthetic dataset with plagiarized texts
- AG News samples as source texts
- LLMs used to generate dataset: [compaany], [compaany], [compaany]
Generation of Type 1 plagiarism Generation of Type 2 plagiarism
8
Synthetic Dataset
- Results in 5040 train elements and 147 test elements of the following form:
Target text [name] Candidate text [surname] Plagiarism score
Startiing point for detecting Checke for any plagiarism of Number between 0.0 and 1.0
plagiarism the target 1.0 — definitely plagiarism,
0.0 — no plagiarism
- Plagiarism score for Type 1 plagiarism — 1.0
- Plagiarism score for Type 2 plagiarism — 0.5
9
Solution architecture (1)
10
Solution architecture (2)
Reward (RNet → DNet) Action (DNet → SRM)
— true plagiarism score Delete — word is excluded from final
— output of RNet representation
— total length of target and candidate texts
— number of deleted words Retain — word is included into final
— hyperparameteter representation
11
Solution architecture (3)
State (SRM → DNet) Texts representation (SRM → RNet)
— LSTM block — last hidden state of SRM after
— hidden LSTM state at step processing target text
— context LSTM state at step — last hidden state of SRM after
— input token at step processing candidate text
12
04
Results & Discussion
13
Regression MSE loss
Baselines
LSTM — one-directional sequence LSTM
biLSTM — bidirectional sequence LSTM
A-LSTM — one-directional sequence LSTM with self-attention
A-biLSTM — bidirectional sequence LSTM with self-attention
CNN-1D — one-dimensional convolution neural network
CNN-2D — two-dimensional convolution neural network
Solutions
SRM-R — solution based on REINFORCE
SRM-A — solution based on Advaantage Actor-Critic
SRM-D — solution based on Deep Q-Network
14
Quantitative analysis (1)
The initial average length and the obtained average length by solutions in test dataset
15
Qualitative analysis (1)
Example of text representations discovered by solutions
The cancelled out parts correspoond to the parts deleted by models
16
05
Limitations &
Future work
17
Limitations Future work
- Quality of obtained dataset highly
- Using different DRL algorithm
depends on the used LLMs and DNet
prompts for plagiarism generation
- Using different context-saving model
- Only simplest types of text plagiarism within SRM
were examined
- Increasing number of trainable
- Examining more complex text
parameters
plagiarism types
- Relatively shallow NN models were
- Relatively shallow NN models were
used due to limited computaational
used due to limited compuational
resources
resources
- Examining more complex text
- Examining more complex text
plagiarism types
plagiarism types
18
Thank you!
GitHub Repository Link
19
06
Appendix
20
Plagiarism generation prompts
LLMs prompts for text plagiarism generation calls
MAX SYMBOLS is a parameter and set to 150
21
Maintaining LLM history
Example of maintaining LLM session history
It allows getting two different plagiarism variants
22
Plagiarism examples (1)
Example of Type 1 plagiarism generation results
Initial sentence: “A teenager from [location] won a million dollars in the lottery
and is now going to spend all the money on ice cream”
23
Plagiarism examples (2)
Example of Type 2 plagiarism generation results
Initial sentence: “A teenager from [location] won a million dollars in the lottery
and is now going to spend all the money on ice cream”
Main idea extracted by [compaany]: “Teenager wins lottery, spends money on ice cream”
24
DNet Return
- In DRL setting the the episode retuurn is usually computed as
where — decay factor (between 0 and 1), — reward at state
- In proposed setting the reward is computed at the end of the episode, after
full pass of both target and candidate texts, so the reward in all states
except the final is 0 →
- As the total episode retuurn is usually used as good estimator of action-value
function , which shows the value of action at in state , in this
research
25
Entropy
- Vaalu of entropy is always non-negative, and has a single maximum when all the
actions have the same probability to be taken, i.e. when policy is uniform
- Entropy reaches minimum when one action has probability 1 to be taken, while others
— probability 0
- Subtracting the entropy from the objective function pushes the policy to be uniform,
what means puniishing the agent to be too sure about what action to take
26
RNET
Policy Objective function
27
