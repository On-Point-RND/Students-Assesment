Trade model
[name], [surname]
Author: [name] [surname]
1/24
Overview of the area
Currently, high–frequency trading
algorithms are popular (there are
even trading robot competitions) -
this is effective, but due to the need
for fast calculations (neural networks
do not count instantly), the algorithm
is often searched for “manually”, and
this takes a very long time.
As for ML solutions, the most
successful attempt was to teach GPT
to analyze financial news.
2/24
Introduction to the field
Swing trading is a type of
trading where positions in
securities are held for several
days, rather than within one
day, while an attempt is made
to predict the trend)
Experienced swing traders
often use a wave approach
based on trend and correction
components.
3/24
Introduction to the field
The task of the model is, in
fact, to learn how to detect
these waves, predict the
moment when the current
wave ends and the next wave
begins.
It is important that the waves
can be of completely different
sizes and amplitudes – this is
the main difficulty.
4/24
Project Description
The project was created to
train the model and automate
its trading on the [location]
Intraday trading –
within one day
Stock Exchange.
Automation is necessary to
trade from multiple brokerage
accounts at the same time.
Trading will be carried out in a
time interval of several days (a Swing trading – a few
type of swing trading) days
5/24
Technologies used
Models: sc learn, cat boot, pytorch, keras
Containization: Docker
Data storage: numpy, pandas
Server operation: flask
Cache: redis
Visualization: seaborn, matplotlib
Parsing and Trading: TinkoffInvest API
6/24
Project architecture
At the moment, the
model is running
autonomously on the
server in test mode on
real current data.
The correct operation
of the parser and
cache is checked.
7/24
Comparative analysis
“Forecasting Gazprom's stock quotes
using LSTM neural networks”
Positive:
● Orientation to the Russian market
Cons:
● Data about only one stock
https://cybberleniinka.ru/article/n/progno
zirovanie-kotirovok-aktsiy-pao-gazprom-
s-ispolzovaniem-neyronnyh-setey-lstm/vi
ewer
8/24
Comparative analysis
“Predicting stock market using LSTM”
Pros:
● A large number of features for the model
● A large number of experiments
Minuses:
● Not suitable for the Russian market
● Predicts quotes not of stocks, but of the
index as a whole.
https://www.sciencedirect.com/science/a
rticle/pii/S2666827022000378
9/24
Comparative analysis
“A Multi Parameter Forecasting for Stock
Time Series Data Using LSTM and Deep
Learning Model”
Positive:
● Consideration of several neural network
architectures (RN, LSTM, CNN)
Minuses:
● Not suitable for the Russian market
● Predicts quotes not of stocks, but of the
index as a whole.
https://www.mdpi.com/2227-7390/11/3/
590
10/24
Data collection
The quotation data is
taken for companies with
capitalization > 300 billion.
(more than 35 companies),
the period from 2004 to
2023
An auxiliary table with
company stock parameters
(ticker, figi, etc.) has been
compiled.
*Note: figi is a unique ID that
exists for each financial
instrument.
11/24
Data preprocessing
Necessity: random events can create
temporary fluctuations in exchange
rates that do not affect the overall
trend
Solution:
● using a moving average
(window size = 3)
● removal threshold (4.5% taken)
● restriction threshold (2% taken)
● normalization
12/24
Model Overview: the beginning
I have experimented with models made only of linear layers (up
to 7) – they are not suitable for my task
ARIMA is also too simple
recurrent neural networks*:
● RNN
● GRU
● LSTM
*for the purity of the experiment, not only torch was used, but
also keras
FAILURE: lack of training
13/24
Catboost: the first successes
After the failure with RNN, it was
important to check whether the data
was suitable for training models in
principle.
Selected parameters:
number of days = 10
max_depth = 5
loss_func = MS
num_trees = 200
Here and further, MAE was used to
evaluate the quality The margin of error for MAE ~ 31,42
red - preds
green- real
14/24
Convolutional neural networks
Unlike RNN, CNN was
implemented only on Keras
(more user-friendly interface)
Selected parameters:
loss_func = MAE
optimizer = Adam
batch_size = 64
n_epochs = 50
number of days = 20
MAE ~ 29,9
красный предсказания
-
зеленый реальные
15/24
Выбор порога для
CNN
Вероятность того что реальное значение и соответственно при условии что
, ≤ Y ( ≥ Y) ,
модель предсказала т е ось истинные значения предсказанные напр
X ( . . Oy - , Ox - , . P(real ≥
17/24
Y | pred ≥ X))
21
Transformer
Transformer turned out to be
no better than CNN
Selected parameters:
loss_func = MAE
optimizer = Adam
n_heads = 8
n_epochs = 50
days: 20, 10, 5
According to the results of the
experiments, CNN is currently
the main one.
Погрешность по МАЕ
~ 30,1
красный предсказания
-
зеленый - реальные 17/24
Choosing the threshold for the transformer
Вероятность того что реальное значение и соответственно при условии что
, ≤ Y ( ≥ Y) ,
модель предсказала т е ось истинные значения предсказанные напр
X ( . . Oy - , Ox - , . P(real ≥
18/24
Y | pred ≥ X))
Example
19/24