Slide 1
----------------------------------------
[name] [surname]
ML Engineer, [compaany]
Tuning LLMs in secure code generation

Slide 2
----------------------------------------
Introduction

Why is this important?
• 83% of [compaany] use AI to generate code [1, 2]
• 63% are conside[name]ing a ban due to security risks [1]
• 25% of [compaany]'s code is already generated by AI [3]

Average number of insecu[name]e code test cases passed across 7 LLMs [4]

Slide 3
----------------------------------------
Problem statement

What are we solving?
LLMs often generate code with vulnerabilities (SQL injection, buffer ove[name]ow)
Developers skip minimum 10% of errors during manual review [4]
Challenges:
Errors in training data → models learn from vuln[name]able examples [5]
There is no "built-in" security verification mecha[name]ism in LLM
The scale of the problem:
40% of AI code contains critical vulnerabilities [4]
60% of data leaks are due to software vulnerabilities [6]
Average damage from the incident: $4.45 million [7]

Slide 4
----------------------------------------
Methods

Iterative Static Analysis
Svace checks code → LLM corrects (2–3 cycles).
DPO Fine-tuning
Trains Qwen2.5 Coder model on "bad → good" code pairs.

Why these methods?
Svace: Catches bugs pre-runti[name].
DPO: Faster/more stable than RLHF.

Iterative feedba[name] system illustration [8]

Slide 5
----------------------------------------
Results

Error-Free Rate (EFR) and pass@1 metric for fine-tuned and original models [8]

Number of corre[name]y generated codes and pass@1 metric on HumanEval benchma[name]k after iterative code patching [8]

Key findi[name]gs:
The DPO approa[name] allowed us to reduce the number of errors by 20%
On MultiEval (our dataset) model has written 6% more valid code, on HumanEval - 2%
Pass@1 metric increased by 2% on HumanEval dataset without feedba[name] approa[name] and by 4% with.
The finetunedmodel began to correct errors faster using the feedba[name] approa[name].

Slide 6
----------------------------------------
Results

Key findi[name]gs:
The DPO approa[name] allowed us to reduce the number of errors by 20%
Complete elimination of errors such as "Variable with zero value"
New vulnerabilities ("Buffer ove[name]ow") = dynamic analysis is required

Error distributions for original and fine-tuned models [8]

Slide 7
----------------------------------------
Research gap

Key points:
Risk reduction: Fewer vulnerabilities → fewer bug fixes.
Accelera[name]ing develo[name]ment: Automatic code verification saves engineers time.
Plans:
Add dynamic analysis (for example, fuzzing).
Expand langua[name]e support (C++, Rust).

Slide 8
----------------------------------------
Venafi. Organizations Struggle to Secu[name]e AI-Generated and Open Source Code. Research report, https://venafi.com/lp/organizations-struggle-to-secu[name]-ai-generated-and-open-source-code/, 2024
Becker, B.A., Denny, P., Finnie-Ansley, J., Luxton-Reilly, A., Prather, J., Santos, E.A.: Programming is hard-or at least it used to be: Educational oppo[name]unities and challenges of ai code generation. In: Proceedings of the 54th ACM Technical Symposium on Computer Science Education V. 1. pp. 500–506, 2023.
Mckenna, G.: Over 25pichai says it’s just the start. Fortune, 2024
Bhatt,M.,Chennabasappa,S.,Nikolaidis,C.,Wan,S.,Evtimov,I.,Gabi,D.,Song, D., Ahmad, F., Aschermann, C., Fontana, L., et al.: Purple llama cyberse[name]eval: A secure coding benchma[name]k for langua[name]e models. arXiv preprint arXiv:2312.04724, 2023
Ji[name] Li, Zhuo Li, HuangZhao Zhang, Ge Li, Zhi Jin, Xing Hu, and Xin Xia. Poison attac[name] and poison detection on deep sou[name]e code processing models. ACM Transactions on Software Engineering and Metho[name]ology, 2023
NIST, Cybercrime To Cost The World $10.5 Trillion Annually By 2025 Special Report, https://cybersecu[name]ityventures.com/cybercrime-damages-6-trillion-by-2021/
IBM. Cost of Data Breach Report, https://www.ibm.com/reports/data-breach, 2024
[name] [surname], Daniel Shaikhelislamov, Arseniy Semkin, Oleg Rogov. Tuning LLM is secure code generation, 19th International Symposium on Neural Networks, 2025

Bibliography